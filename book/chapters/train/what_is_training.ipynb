{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6943c2",
   "metadata": {},
   "source": [
    "# Training Models for TinyML\n",
    "When training models for large systems, we almost always focus on improving the accuracy of the model. Two methods that will almost always increase your model's accuracy are to either use more high quality data or to use larger models with complex layers, operations and data flows. In the first case, we have already talked about how data can be collected and preprocessed as well as how we can apply feature engineering techniques to improve the performance of TinyML models. However, when we train models for TinyML, we cannot use large and complex custom layers. In fact, we cannot use most of the commonly available model architectures or layers and operations that are typically used in large models since they are not supported on many TinyML devices. This poses a problem since we need to train models such that they can maintain appreciable performance while still being computationally simple and occupy less memory.\n",
    "\n",
    "In this chapter, we will learn more about how we can design and train models such that we can get the least performance degradation when we deploy it to a TinyML device."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
